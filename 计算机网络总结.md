### **OSI七层模型**

应用层：定义了应用之间的消息传输规则，定义了通信的格式

HTTP：基于TCP，超文本传输协议。用于Web浏览器和Web服务器之间的通信。

SMTP:基于TCP协议，简单邮件发送协议，用于发送电子邮件。只负责发送不负责接收。

FTP：文件传输协议，在计算机之前传输文件。但是不安全，不会对数据进行加密，因此如果是敏感数据应该使用SFTP协议。

Telnet:远程登录协议（就是网络传输协议），通过一个终端登录到其他服务器。缺点是数据均以明文的形式发送，有安全风险。

SSH：安全网络传输协议，基于TCP协议，通过加密和认证机制实现安全的访问和文件传输业务。

DNS：基于UDP，解决域名和IP地址映射的问题。





### HTTPS协议

默认端口443

HTTPS通信流程

相较于HTTP协议，它增加了SSL/TLS层，TLS是对SSL的优化，因为SSL本身存在安全问题，现在基本都是支持TLS，基本不支持SSL。

下面这个过程也就是TLS的加密过程。回答的时候就按照这个回答

三个重点：认证机构，服务器，浏览器

![image-20250108133826996](C:\Users\17898\AppData\Roaming\Typora\typora-user-images\image-20250108133826996.png)



### HTTP1.0和HTTP1.1的区别

#### 响应状态码

#### http1.0只支持16种状态码，http1.1新增了24种状态码。

#### 缓存技术

主要是为了避免用户与服务器的频繁交互，节约了大量网络带宽，降低用户接收延迟。

Expires:过期时间，由服务端生成。

Last-Modified:资源地上次修改时间，服务端维护，但是会和Expires一起在第一次请求资源的时候返回给浏览器。

If-Modified-Since:浏览器缓存地上次服务器返回的Last-Modified。

在HTTP1.0种缓存技术地实现是依赖服务端返回的Expires和Last-Modified字段。

每次请求相同的资源，浏览器会根据缓存的Expires，如果没有超过这个时间会直接使用上一次缓存的资源，如果超过这个时间则会再一次向浏览器发送请求报文，浏览器收到请求后会根据报文头种携带的If-Modified-Since（上次服务器响应返回给浏览器的Last-Modified)来和对应资源地Last-Modified进行比较，如果过期，则返回给浏览器最新的资源。如果没有过期，则返回状态码304 not modified，表示浏览器还是可以用之前的缓存。

![1736318590560](C:\Users\17898\Documents\WeChat Files\wxid_ilsb8mab1nud22\FileStorage\Temp\1736318590560.png)

HTTP1.1相较于HTTP1.0在Header头部引入了Cache-Control字段，使得缓存的灵活性大大增强，拥有多种缓存策略，例如no-store不允许缓存，public可以被缓存,private不允许中间代理缓存运训客户端缓存等等。还有对If-Modified-Since做了增强。



#### 连接方式

HTTP1.0默认使用短连接，也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。这样会导致在建立TCP连接的时候会有大量的握手报文和挥手报文占据带宽。但是HTTP1.0仍然提供了长连接选项，可以在请求头种加入Connection: Keep-alive.

而HTTP1.1默认使用的是长连接，连接之后建立成功后，可以不关闭连接而是持续打开，方便后续的客户端-服务端数据交互，即如果下次客户端还要访问这个服务器。可以继续复用已经建立好的连接。如果不希望使用长连接选项，也可以在请求头中加入`Connection: close`。

所谓长连接或者短连接 实质上也是TCP协议的长连接和短连接。



#### Host头处理

域名系统支持多个主机绑定到同一个IP上，HTTP1.0没有考虑这个问题，因此只请求同一个域名，解析完毕后得到IP但是不知道到底对应哪一个主机。

HTTP1.1支持HOST字段，可以指定该IP对应的主机到底是哪个。



#### 范围请求

HTTP/1.1 引入了**范围请求**（Range Request）机制，允许客户端只请求文件的一部分（通常是字节数据）。客户端通过在请求中添加 `Range` 头部来指定需要的部分，服务器返回对应的数据和 `206 Partial Content` 状态码。这个机制主要用于**下载恢复**和**节省带宽**，避免重新下载整个文件。服务端如果支持范围请求，则它会根据请求返回指定的部分数据，并带上相应的 `Content-Range` 头部来告知客户端返回的是数据的哪一部分。如果服务器不支持范围请求，它会忽略 `Range` 头部，返回整个资源而不做切分。



#### 状态码

HTTP/1.1 中新加入了状态码`100`。该状态码的使用场景为，存在某些较大的文件请求，如果请求头部分没有问题（比如认证信息没问题），服务器返回 **100 Continue**，表示客户端可以继续发送请求体，否则返回404等，这样就不用上传这么大的文件请求了，此时状态码`100`可以作为指示请求是否会被正常响应。（实际上就是避免浪费带宽）



### HTTP1.1和HTTP2.0的区别

1.HTTP2.0支持多路复用，同一个连接上可以同时传输多个请求和响应，互不干扰。HTTP1.1支持的是串行方式，同一个请求上每个请求和响应需要独立的连接，即对于一个连接，必须等到上一个请求收到响应结束后才能开始下一个请求。浏览器为了控制资源会有6-8个TCP请求的限制。而HTTP2.0处理多个请求更加高效，减少了网络延迟。

2.HTTP1.1只支持Body的压缩，而不支持Header的压缩，而HTTP2.0支持对Header的压缩，由专门的HPACK算法，能够减少网络开销。

3.服务器推送:HTTP2.0支持客户端在请求一个资源时将相关资源一并推送给客户端，减少客户端请求次数和延迟。而HTTP1.1则需要客户端自己发送请求来获取相关的资源。

**4.HTTP2.0使用二进制帧来传输数据，它更加高效和紧凑，减少传输数据量和带宽。HTTP1.1使用文本格式的报文。**没弄懂



### HTTP2.0和HTTP3.0的区别

HTTP3.0采用了QUIC协议来取代传输层的TCP协议，它是基于UDP的



#### 如何解决HTTP协议的无状态性

1.Session + Cookie,针对每个用户在服务端保存每个用户的信息，然后生成Session ID返回给客户端浏览器，客户端浏览器在下次请求时携带，服务端分局Session ID用来验证用户的身份。如果Cookie被禁用，则将Session ID直接附带在URL后即可。

2.Token,服务端保存Session会浪费内存资源，因为一般是保存在Redis里面，所以可以通过加密算法和签名算法生成Token，将其保存在客户端浏览器，每次携带，服务端仅作验证即可。常见的就是JWT，基于Token的认证授权机制。

JWT组成：Header,Payload,Signature

**Header（头部）**: 描述 JWT 的元数据，定义了生成签名的算法以及 `Token` 的类型。Header 被 Base64Url 编码后成为 JWT 的第一部分。

**Payload（载荷）** : 用来存放实际需要传递的数据，包含声明（Claims），如`sub`（subject，主题）、`jti`（JWT ID）。Payload 被 Base64Url 编码后成为 JWT 的第二部分。

**Signature（签名）**：服务器通过 Payload、Header 和一个密钥(Secret)使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。生成的签名会成为 JWT 的第三部分。

验证流程：

1.用户向服务器发送用户名、密码以及验证码用于登陆系统。

2.如果用户用户名、密码以及验证码校验正确的话，服务端会返回已经签名的 Token，也就是 JWT。

3.用户以后每次向后端发请求都在 Header 中带上这个 JWT 。

4.服务端检查 JWT 并从中获取用户相关信息。

服务端拿到 JWT 之后，会解析出其中包含的 Header、Payload 以及 Signature 。服务端会根据 Header、Payload、密钥再次生成一个 Signature。拿新生成的 Signature 和 JWT 中的 Signature 作对比，如果一样就说明 Header 和 Payload 没有被修改。如果密钥被窃取了则没办法了。。。。

JWT的优点：

1.本身你能够包含身份验证所需要的所有信息，因此可以不在服务器在存储JWT的信息，大大减轻了服务端的压力。

2.能够防止跨站请求伪造，因为JWT在LocalStorage中存储，只有当请求代码明确指出需要携带JWT才会携带，而不需要Cookie了，但是CSRF攻击需要依赖Cookie。不过，这样也会存在 XSS 攻击的风险。为了避免 XSS 攻击，你可以选择将 JWT 存储在标记为`httpOnly` 的 Cookie 中。但是，这样又导致了你必须自己提供 CSRF 保护，因此，实际项目中我们通常也不会这么做。

`HttpOnly` 是一个 **cookie 属性**，它的作用是 **禁止 JavaScript 访问该 cookie**，从而防止 **XSS 攻击** 窃取存储在 cookie 中的敏感数据

3.适用于移动端，使用 Session 进行身份认证的话，需要保存一份信息在服务器端，而且这种方式会依赖到 Cookie（需要 Cookie 保存 `SessionId`），所以不适合移动端。

但是，使用 JWT 进行身份认证就不会存在这种问题，因为只要 JWT 可以被客户端存储就能够使用，而且 JWT 还可以跨语言使用。



JWT的缺点：

1.用户都退出登录了，JWT还有效

解决方法：1.维护一个黑名单，存到Redis里面，过期的直接不管了。

​       2.更换密钥。

​        3.用户的登录有效状态时间不要设置太长，即JWT的有效时间不要设置太长。

2.JWT 结构复杂（Header、Payload 和 Signature），包含了更多额外的信息，还需要进行 Base64Url 编码，这会使得 JWT 体积较大，增加了网络传输的开销。

解决办法：

- 尽量减少 JWT Payload（载荷）中的信息，只保留必要的用户和权限信息。
- 在传输 JWT 之前，使用压缩算法（如 GZIP）对 JWT 进行压缩以减少体积。
- 在某些情况下，使用传统的 Token 可能更合适。传统的 Token 通常只是一个唯一标识符，对应的信息（例如用户 ID、Token 过期时间、权限信息）存储在服务端，通常会通过 Redis 保存。





### HTTP协议和UDP，TCP的关系

HTTP3.0之前，HTTP协议都是基于TCP协议实现的，在HTTP3.0改为了基于UDP实现的QUIC协议。

变化的原因主要是，在HTTP2.0中，引入了多路复用机制，建立多个数据流，解决了HTTP1.1中线性发送请求的问题，很大程度上缓解了队头阻塞的问题。但是多路复用虽然允许同时发送和接收多个请求与响应。但多个数据流在其底层还是基于同一个TCP连接，因此，当出现多个请求同时发送，如果其中某个请求的数据包丢失，接收方会请求重传这个数据包，这也意味着会阻塞其他请求的数据包继续发送。

### **如何理解“队头阻塞”**：（队列头部的元素无法被处理，导致其余元素也无法处理）

假设你有一个队列：A1, A2, A3, B1, B2, B3, C1, C2, C3........

- **A1** 是队列的第一个元素（队头元素）。
- **A2, A3** 是它后面的元素。

如果 **A2 丢失了**，在 **TCP** 中，由于它的 **顺序要求**，接收方会**等到 A2 重传**，这个时候假设发送方发送到C1了，那C2,C3及其之后的都会被阻塞导致无法发送。

HTTP3.0弃用TCP，开发了基于UDP的QUIC协议，它进一步解决了队头阻塞的问题。具体是它在一个连接上建立多个数据流，但是这些数据流之间互不干扰，某个数据流发生了包的丢失，不会影响其他数据流。



### TCP为什么要三次握手，为什么不是两次？

由于TCP是可靠的，全双工的，允许双方同时接收和发送数据，因此，无论接收方还是发送方，都要确认自己和对方的接收功能和发送功能是正常的可用的。这样才能保证可靠。

![TCP 三次握手图解](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-shakes-hands-three-times.png)

第一次握手：客户端发送seq = x,SYN = 1发送给服务端，客户端进入SYN_SEND状态。

第二次握手：服务端收到后，回复seq = y,SYN = 1,ACK = 1,ack = x + 1给客户端，服务端进入SYN_RECV状态。

（这里为什么要传SYN，其实我自己的理解是因为TCP本身全双工，SYN是建立连接发起的握手信号，如果要建立A - > B的连接，那么就必须先发起SYN，所以现在服务端要建立到客户端的请求，也要发送SYN。所以这一步发送SYN是为了建立并确认服务端到客户端的通信）

第三次握手:  客户端收到后，回复ack = y = 1，ACK = 1给服务端，服务端客户端都进入ESTABLISHED状态。



第一次握手达到的效果就是：客户端啥也不能知道，服务端能够知道服务端接收功能和客户端发送功能是没有问题的。

第二次握手达到的效果是：客户端能够知道自己的发送功能和接收功能都没有问题，服务端发送和接收功能也没有问题。服务端目前还是只能确认自己的接收功能和客户端发送功能没有问题。

第三次握手：服务端和客户端都能确认自己以及对方的接收和发送功能都没有问题。

如果是两次握手，显而易见是无法达到上述要求的，也无法满足最后的要求。



### 半连接和全连接队列是什么？

建立TCP连接需要Linux来辅助，Linux会维护两个队列来管理请求

1.半连接队列：当服务端收到SYN请求后，此时双方没有完全建立连接，会把半连接状态的连接放到半连接队列。

2.全连接队列：当服务端收到客户端的ACK响应，意味着三次握手成功，服务端会将该连接从半连接队列移动到全连接队列，如果长时间没收到ACK，会进行重传（第二次握手），然后再去接收ACK，重传时间指数级增长，如果超过规定重传最大次数，会把这个连接请求从半连接队列中删除。



### TCP为什么是四次握手断开连接？

![TCP 四次挥手图解](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-waves-four-times.png)

第一次握手：客户端向服务端发送seq = u,FIN = 1，请求关闭客户端到服务端的连接，客户端进入FIN_WAIT-1状态

第二次握手：服务端向客户端发送 ACK = 1,ack = u + 1，服务端进入CLOSE-WAIT状态，客户端进入FIN_WAIT-2状态，正式关闭客户端到服务端的连接

第三次握手：服务端向客户端发送FIN = 1,seq = v，服务端进入LAST-ACK状态，请求关闭服务端到客户端的连接

第四次握手：客户端向服务端发送ACK = 1，ack = v + 1，客户端进入TIME-WAIT状态，客户端等待2MSL后如果没有回复，则正式关闭服务端到客户端的连接。



为什么不是三次握手？

其实也是因为TCP是全双工的，当客户端申请关闭其到服务端的连接时，服务端向客户端发送的数据可能还没有传输完毕，因此三次握手会丢失这部分数据。



为什么最后一次握手，客户端需要等待2MSL？

如果ACK丢失的话，服务端会重新发送FIN，客户端只要在2MSL内收到FIN，会重新发送ACK。

**MSL(Maximum Segment Lifetime)** : 一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接。



### TCP的可靠性保证

1.流量控制

TCP报文中有个字段是，接收窗口字段。这个字段可以调整发送方发送到接收方的字节数。从而控制发送方的发送速率。如果窗口大小置为0，则发送方无法再向接收方发送数据，但是会等待一段时间后发送一个试探报文，请求接收方的最新接收窗口设置。流控的主要原因也是因为收发双方的速率不一定相等，如果接收方缓冲区已经满了，发送方再发送数据接收方也无法缓存和接收，反而白白浪费了网络资源。因此流控是协调控制收发双方的数据传输。**接收窗口的大小是根据接收端处理数据的速度动态调整的。** 如果接收端读取数据快，接收窗口可能会扩大。 否则，它可能会缩小。

2.拥塞控制

![TCP的拥塞控制](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-congestion-control.png)

主要是防止过多的数据注入网络，使得网络变得拥挤或者过载。拥塞控制相较于流量控制来说，是一个全局整体的概念。流量控制通常是专注点对点通信量控制。

为了实现拥塞控制，发送方需要维护一个拥塞窗口大小状态变量，并且不断地进行动态的变化，发送方让自己的发送窗口大小取接收方接收窗口和拥塞窗口中较小的一个。

并且TCP协议使用慢开始，拥塞避免，快重传和快恢复四种算法来进行拥塞避免。

慢开始：即刚开始不要发送大量数据到网络中，而是逐步递增，指数级增张知道达到ssthresh(慢启动阈值)，之后线性增长，拥塞窗口的大小在没有发生拥塞之前一直增长，其单位是MSS或者byte,当网络发生拥塞的时候，其大小会迅速下降，此时sshtresh会变为此时拥塞窗口大小的一半。

注：拥塞窗口大小为10MMS的意思是，发送方能够发送最多10个最大数据段大小的数据，可以不等待被确认。

拥塞避免：让cwnd的窗口大小缓慢增大，每经过一个往返的RTT就把发送窗口的cwnd加1。（**每经过一个往返时延（RTT）**，如果没有发生丢包，**cwnd** 会 **增加**）。

快重传和快恢复：当发送方收到三个重复ACK时，发送方会认为这个包丢失了，不会再等到超时才重传丢失的数据包而是立刻重传这个数据包，避免超时带来的延迟。快恢复主要是为了避免丢包后进入慢启动阶段，希望保持一定的传输速度，这个时候会回退到sstresh，而不是从头开始，当收到三个重复的 ACK 时，TCP 会将 **ssthresh**（慢启动阈值）设置为当前 **cwnd** 的一半，然后从这个位置继续发送数据。

3.排序和重传以及数据去重

TCP报文对于每个包都有一个序列号，通过序列号可以进行数据的重新排序，并且实现数据的去重。



### ARQ协议

自动重传请求协议，在发送方发送消息后，如果超过一点时间没有收到确认，会重新发送之前的消息，知道收到确认或者重试超过一定次数。

ARQ协议分成停止等待协议和连续ARQ协议。

#### 停止等待协议

实现可靠传输，当发送方每次发完一个分组的数据后停止发送直到收到该部分消息的确认ACK后再发送下一个分组。如果超过一段时间没有收到ACK确认，则说明消息可能丢失，会重新发送。如果接收方收到消息，必须给发送方回复一个ACK，重复收到消息的时候会丢掉这个消息，同时再次返回对这个消息的ACK确认。此时发送方如果已经收到过这个消息的ACK，则会直接丢弃ACK。



#### 连续ARQ协议

收发双方分别维护一个窗口，窗口内的分组数据均可以发送，发送方可以连续发送多个分组数据，接收方也可以接收多个分组数据，采用累计确认的方法，对按序到达的最后一个分组发送确认，表明到这个分区为止的所有分组都已经正常接收了。

优点：信道利用率高，效率更高。

缺点：发送方无法确认接收方具体收到的分组情况，因为是累计确认，发送方可能会重传接收方已经收到的分组信息。



#### 超时重传如何实现？

主要是利用一个定时器，如果超过这个时间，则会重传分组数据，这个超时时间会被动态调整。





### IP协议

网络层协议，可以定义数据包格式，对数据包进行路由和寻址，可以跨网络传播到正确目的地。

分两种：IPv4和IPv6

IPv4:32位，不够用耗尽了快。

解决方法：NAT，网络前缀，IPv6等。

IPv6：128位，不需要依赖DHCP，主机可以拥有全局唯一的IPv6。NAT成为可选项，因为IPv6的地址足够多。



NAT的作用：将私有地址映射成为公有地址或者反向映射。实现通过局域网访问互联网。隐藏局域网的拓扑结构，提高网络安全性。



### ARP协议

MAC地址：一切网络设备的唯一地址。48bit

ARP 协议，全称 **地址解析协议（Address Resolution Protocol）**，它解决的是网络层地址和链路层地址之间的转换问题。因为一个 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 IP 地址属于逻辑地址，而 MAC 地址才是物理地址，ARP 协议解决了 IP 地址转 MAC 地址的一些问题。

工作原理(过程)：

当A主机发送一个请求数据包想要到达B主机，在数据链路层，目前A不知道B的MAC地址，即在ARP表中没有B的ip对应的MAC地址，此时A会广播一个ARP请求包，这个包里面有A的ip,A的MAC地址，还有B的ip地址，其他主机收到这个之后，会把A的ip和对应的MAC地址写入自己的ARP表，B收到这个时候，会记录A的ip和MAC地址对应关系，然后把自己的IP和MAC单播给A，此时A将把B的IP地址和MAC地址写入自己的ARP表，然后再转发之前的请求数据包到B。

FF-FF-FF-FF-FF-FF是一个特殊MAC地址，即广播地址。
